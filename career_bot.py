import os
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_openai import ChatOpenAI
import time
import textwrap
from dotenv import load_dotenv

# Load environment variables from the .env file
load_dotenv()

# Explicitly disable LangSmith tracing
os.environ["LANGCHAIN_TRACING_V2"] = "false"

# --- PROMPT DEFINITIONS for Mode 1: Exploration ---
PROMPTS = {
    1: {
        "title": "é˜¶æ®µä¸€ï¼šå¯åŠ¨ä¸å¯¼å…¥ â€”â€” â€œæˆ‘æ˜¯è°ï¼Ÿâ€",
        "prompt": """ä½ å¥½ï¼æˆ‘æ˜¯ä¸€æ¬¾èŒä¸šç›®æ ‡è§„åˆ’è¾…åŠ©AIã€‚æˆ‘å°†é€šè¿‡ä¸€ä¸ªç»è¿‡éªŒè¯çš„åˆ†ææ¡†æ¶ï¼Œå¼•å¯¼ä½ æ›´å…·ä½“ã€æ›´ç³»ç»Ÿåœ°æ€è€ƒâ€˜èŒä¸šç›®æ ‡æ˜¯æ€ä¹ˆæ¥çš„â€™ï¼Œå¹¶æœ€ç»ˆæ‰¾åˆ°å±äºä½ è‡ªå·±çš„æ–¹å‘ã€‚

è®©æˆ‘ä»¬ä»æ ¸å¿ƒå¼€å§‹ï¼Œä¹Ÿå°±æ˜¯â€˜æˆ‘â€™ã€‚è¯·ä½ ç”¨å‡ ä¸ªå…³é”®è¯æˆ–çŸ­å¥å…·ä½“æè¿°ä¸€ä¸‹ï¼š

1. ä½ çš„ä¸“ä¸š/ä¸ªäººå…´è¶£ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ
2. ä½ è®¤ä¸ºè‡ªå·±æœ€æ“…é•¿çš„ä¸‰é¡¹èƒ½åŠ›æ˜¯ä»€ä¹ˆï¼Ÿ
3. åœ¨æœªæ¥çš„å·¥ä½œä¸­ï¼Œä½ æœ€çœ‹é‡çš„æ˜¯ä»€ä¹ˆï¼Ÿ(å¯å¤šé€‰)"""
    },
    2: {
        "title": "é˜¶æ®µäºŒï¼šå¯åˆ†æå› ç´ è§£æ„ â€”â€” â€œæˆ‘æ‹¥æœ‰ä»€ä¹ˆå¹³å°å’Œæœºä¼šï¼Ÿâ€",
        "prompt": """ç°åœ¨ï¼Œæˆ‘ä»¬æ¥åˆ†æä¸€äº›ä½ å¯ä»¥é˜¶æ®µæ€§å®¡è§†çš„å¤–éƒ¨å› ç´ ã€‚

1. å…³äºã€å¤§å­¦å¹³å°ã€‘:
   * ä½ æ‰€åœ¨çš„å¤§å­¦æˆ–ä¸“ä¸šï¼Œåœ¨å“ªäº›é¢†åŸŸè¢«è®¤ä¸ºæ˜¯ä¼˜åŠ¿å­¦ç§‘ï¼Ÿ
   * é€šå¸¸æœ‰å“ªäº›ç±»å‹çš„ä¼ä¸šä¼šæ¥ä½ ä»¬å­¦æ ¡æˆ–å­¦é™¢è¿›è¡Œæ‹›è˜ï¼Ÿè¿™ç»™äº†ä½ ä»€ä¹ˆå…·ä½“çš„å¯å‘ï¼Ÿ
   * ä½ æ‰€åœ¨çš„åŸå¸‚ä¸ºä½ æä¾›äº†å“ªäº›ç‹¬ç‰¹çš„äº§ä¸šæœºä¼šï¼Ÿ

2. å…³äºã€è¶‹åŠ¿ã€‘:
   * ä½ æ³¨æ„åˆ°äº†å“ªäº›æ­£åœ¨å‘ç”Ÿçš„ç¤¾ä¼šæˆ–æŠ€æœ¯è¶‹åŠ¿ï¼Ÿ
   * è¯·å…·ä½“æ€è€ƒï¼Œè¿™äº›è¶‹åŠ¿å¯èƒ½ä¼šå‚¬ç”Ÿå‡ºå“ªäº›ä¸ä½ çš„ä¸“ä¸šæˆ–å…´è¶£ç›¸å…³çš„**æ–°è¡Œä¸š**æˆ–**æ–°å²—ä½**ï¼Ÿ

3. å…³äºã€æœºç¼˜ã€‘:
   * å›æƒ³ä¸€ä¸‹ï¼Œæ˜¯å¦æœ‰æŸæ¬¡å¶ç„¶çš„ç»å†è®©ä½ å¯¹æŸä¸ªèŒä¸šé¢†åŸŸäº§ç”Ÿäº†æ–°çš„å…´è¶£ï¼Ÿ"""
    },
    3: {
        "title": "é˜¶æ®µä¸‰ï¼šéœ€æŒç»­è§‰å¯Ÿå› ç´ çš„æŒ–æ˜ â€”â€” â€œæˆ‘è¢«ä»€ä¹ˆæ‰€å½±å“ï¼Ÿâ€",
        "prompt": """æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬æ¢è®¨ä¸€äº›éœ€è¦æŒç»­â€˜è§‰å¯Ÿâ€™çš„ã€æ›´æ„Ÿæ€§çš„å½±å“å› ç´ ã€‚

1. å…³äºã€å®¶åº­ä¸ç¤¾ä¼šæœŸå¾…ã€‘:
   * ä½ çš„é•¿è¾ˆæˆ–å®¶åº­å¯¹ä½ çš„èŒä¸šæœ‰ä»€ä¹ˆ**å…·ä½“**çš„æœŸæœ›å—ï¼Ÿ
   * ä½ èº«è¾¹çš„æœ‹å‹æˆ–â€˜åœˆå­â€™ï¼Œä»–ä»¬çš„èŒä¸šè§„åˆ’æ˜¯æ€æ ·çš„ï¼Ÿè¿™å¯¹ä½ äº§ç”Ÿäº†ä»€ä¹ˆå½±å“ï¼Ÿ

2. å…³äºã€æ¦œæ ·ã€‘:
   * æ˜¯å¦æœ‰ä½ éå¸¸æ•¬ä½©çš„æŸä¸ªæ¦œæ ·äººç‰©ï¼Ÿ
   * ä½ æ¬£èµçš„æ˜¯ä»–/å¥¹çš„**èŒä¸šæœ¬èº«**ï¼Œè¿˜æ˜¯ä»–/å¥¹å·¥ä½œå¸¦æ¥çš„æŸç§**çŠ¶æ€**æˆ–å…¶**â€˜å‘¨è¾¹â€™**ä»·å€¼ï¼Ÿ"""
    },
    4: {
        "title": "é˜¶æ®µå››ï¼šæ ¸å¿ƒä¸‰è§’å…³ç³»æ•´åˆä¸å†³ç­–æ¨¡æ‹Ÿ",
        "prompt": """éå¸¸æ£’çš„æ·±å…¥æ€è€ƒï¼ç°åœ¨ï¼Œè®©æˆ‘ä»¬æŠŠè¿™äº›ç¢ç‰‡åŒ–çš„ä¿¡æ¯æ•´åˆèµ·æ¥ã€‚

æ ¹æ®æˆ‘ä»¬ä¹‹å‰çš„å¯¹è¯ï¼Œæˆ‘ä¸ºä½ åšä¸€ä¸ªç®€å•çš„å›é¡¾ä¸æ€»ç»“ï¼š
{history}

**å†³ç­–æ¨¡æ‹Ÿï¼š**
1. ç»“åˆä»¥ä¸Šæ‰€æœ‰ä¿¡æ¯ï¼Œè¯·å°è¯•æ„æ€1-2ä¸ªå¯èƒ½çš„èŒä¸šæ–¹å‘ã€‚
2. é’ˆå¯¹ä½ æ„æ€çš„èŒä¸šæ–¹å‘ï¼Œæˆ‘ä»¬æ¥æ€è€ƒä¸€ä¸ªéå¸¸ç°å®çš„é—®é¢˜ï¼š**â€˜å¦‚ä½•(æ”¶å…¥)â€™**ã€‚ä½ æœŸæœ›çš„å›æŠ¥æ˜¯ä»€ä¹ˆï¼Ÿ
3. å¦‚æœä½ çš„ç†æƒ³æ–¹å‘ä¸å®¶åº­æœŸå¾…å­˜åœ¨çŸ›ç›¾ï¼Œä½ è®¤ä¸ºå¯ä»¥æ”¶é›†å“ªäº›ä¿¡æ¯æ¥å’Œå®¶äººå¼€ä¸€æ¬¡æœ‰ç†æœ‰æ®çš„â€˜å®¶åº­ä¼šè®®â€™å‘¢ï¼Ÿ"""
    },
    5: {
        "title": "é˜¶æ®µäº”ï¼šæ€»ç»“ä¸è¡ŒåŠ¨ â€”â€” â€œå¦‚ä½•åšåˆ°åšå®šè€Œçµæ´»ï¼Ÿâ€",
        "prompt": """æˆ‘ä»¬çš„æ¢è®¨å³å°†ç»“æŸã€‚èŒä¸šè§„åˆ’ä¸æ˜¯ä¸€æ¬¡æ€§çš„ç»ˆç‚¹ï¼Œè€Œæ˜¯ä¸€ä¸ªæŒç»­ä¼˜åŒ–çš„è¿‡ç¨‹ã€‚æ ¸å¿ƒæ˜¯è¾¾åˆ°**â€˜åšå®šè€Œçµæ´»â€™**çš„çŠ¶æ€ã€‚

è¯·è®°ä½ï¼Œå¤§å­¦é˜¶æ®µæ˜¯è¿›è¡ŒèŒä¸šæ¢ç´¢å’Œâ€˜è¯•é”™â€™æˆæœ¬æœ€ä½çš„æ—¶æœŸã€‚ä¸ºäº†éªŒè¯æˆ‘ä»¬ä»Šå¤©è®¨è®ºå‡ºçš„èŒä¸šæ–¹å‘ï¼Œä½ å¯ä»¥ç«‹å³é‡‡å–çš„**ç¬¬ä¸€ä¸ªå°æ­¥éª¤**æ˜¯ä»€ä¹ˆï¼Ÿ

* A. é€šè¿‡å®ä¹ æˆ–å‹¤å·¥ä¿­å­¦å»äº²èº«ä½“éªŒï¼Ÿ
* B. æ‰¾ä¸€ä½è¯¥é¢†åŸŸçš„å­¦é•¿å­¦å§æˆ–ä»ä¸šè€…æ·±å…¥äº¤æµï¼Ÿ
* C. å­¦ä¹ ä¸€é¡¹ä¸è¯¥æ–¹å‘ç›¸å…³çš„å…·ä½“æŠ€èƒ½ï¼Ÿ
* D. å…¶ä»–ï¼š__________

è¯·é€‰æ‹©å¹¶å…·ä½“æè¿°ä½ çš„è¡ŒåŠ¨è®¡åˆ’ã€‚"""
    }
}


# --- Helper Functions ---
def print_formatted(text, prefix="AI: "):
    """Helper function to print text with wrapping."""
    wrapped_text = textwrap.fill(text, width=80, subsequent_indent='    ', replace_whitespace=False)
    print(f"\n{prefix}{wrapped_text}\n")


def get_llm_instance():
    """Initializes and returns the LLM instance."""
    api_key = os.getenv("DEEPSEEK_API_KEY")
    if not api_key:
        print("\n" + "â”€" * 80)
        print(">>>>> é”™è¯¯ï¼šæœªæ‰¾åˆ°APIå¯†é’¥! <<<<<")
        print("\nè¯·ç¡®è®¤æ‚¨çš„é¡¹ç›®æ–‡ä»¶å¤¹ä¸­åŒ…å« .env æ–‡ä»¶ï¼Œå¹¶ä¸”è¯¥æ–‡ä»¶ä¸­å·²è®¾ç½® DEEPSEEK_API_KEYã€‚")
        print("â”€" * 80 + "\n")
        return None

    try:
        llm = ChatOpenAI(
            model="deepseek-r1-250528",
            temperature=0.7,
            api_key=api_key,
            base_url="https://ark.cn-beijing.volces.com/api/v3"
        )
        print("æ­£åœ¨è¿æ¥ç«å±±æ–¹èˆŸï¼ˆVolcEngine Arkï¼‰API...")
        llm.invoke("Hello")
        print("è¿æ¥æˆåŠŸï¼")
        return llm
    except Exception as e:
        print("\n" + "â”€" * 80)
        print(">>>>> åˆå§‹åŒ–æ¨¡å‹æ—¶å‡ºé”™! <<<<<")
        print(f"Error Details: {e}")
        return None


# --- Mode 1: Career Goal Exploration ---
def run_exploration_mode(llm):
    """Runs the 5-stage career exploration conversation."""
    store = {}

    def get_session_history(session_id: str) -> ChatMessageHistory:
        if session_id not in store:
            store[session_id] = ChatMessageHistory()
        return store[session_id]

    current_stage = 1
    while current_stage <= len(PROMPTS):
        stage_info = PROMPTS[current_stage]
        title = stage_info["title"]
        system_prompt = stage_info["prompt"]

        if current_stage == 4:
            history_messages = get_session_history("exploration_session").messages
            history_summary = "\n".join([f"{msg.type.capitalize()}: {msg.content}" for msg in history_messages])
            final_system_prompt = system_prompt.format(history=history_summary)
        else:
            final_system_prompt = system_prompt

        meta_prompt = f"""You are a thoughtful and insightful career planning coach. Your goal is to help the user think more deeply about their answers based on a five-stage framework. After the user answers the questions for a stage, provide a brief, insightful comment or a thought-provoking follow-up question that connects their answer to the underlying principles of the framework. Keep your feedback concise (2-3 sentences).

You are currently in Stage {current_stage} of the process. The user is answering the following questions:
{final_system_prompt}
"""
        prompt = ChatPromptTemplate.from_messages(
            [("system", meta_prompt), MessagesPlaceholder(variable_name="history"), ("human", "{input}")])
        chain = RunnableWithMessageHistory(prompt | llm, get_session_history, input_messages_key="input",
                                           history_messages_key="history")

        print("â”€" * 80)
        print(f"                                   {title}")
        print("â”€" * 80)

        if current_stage == 1:
            print_formatted(system_prompt, prefix="")

        print("\nğŸ’¡ è¯·é’ˆå¯¹ä»¥ä¸Šé—®é¢˜ï¼Œå°†ä½ çš„æƒ³æ³•å’Œæ€è€ƒä¸€æ¬¡æ€§è¾“å…¥ï¼Œç„¶åæŒ‰Enteré”®ã€‚")
        user_input = input("ä½ çš„å›ç­”: ")

        if user_input.lower() in ['quit', 'exit']:
            print_formatted("å¥½çš„ï¼Œå¯¹è¯ç»“æŸã€‚æ­£åœ¨è¿”å›ä¸»èœå•...")
            break

        print("\n[AIæ­£åœ¨åˆ†ææ‚¨çš„å›ç­”å¹¶æä¾›å»ºè®®ï¼Œè¯·ç¨å€™...]")
        response = chain.invoke({"input": user_input}, config={"configurable": {"session_id": "exploration_session"}})
        print_formatted(response.content)

        time.sleep(2)
        current_stage += 1

        if current_stage <= len(PROMPTS):
            print_formatted(PROMPTS[current_stage]["prompt"], prefix="")

    print("â”€" * 80)
    print("èŒä¸šç›®æ ‡æ¢ç´¢æµç¨‹å·²å®Œæˆã€‚æ­£åœ¨è¿”å›ä¸»èœå•...")
    print("â”€" * 80)


# --- Mode 2: Offer Decision Support ---
def run_decision_support_mode(llm):
    """Guides the user to analyze and compare job offers."""
    print("\n" + "â”€" * 80)
    print("                                 æ¨¡å¼äºŒï¼šOfferå†³ç­–åˆ†æ")
    print("â”€" * 80)
    print_formatted("ä½ å¥½ï¼å½“ä½ æ‰‹æ¡å¤šä¸ªOfferçŠ¹è±«ä¸å†³æ—¶ï¼Œæˆ‘å¯ä»¥é€šè¿‡ç»“æ„åŒ–çš„æ–¹å¼ï¼Œå¸®åŠ©ä½ ç†æ¸…æ€è·¯ï¼Œåšå‡ºæ›´é€‚åˆè‡ªå·±çš„é€‰æ‹©ã€‚")

    offer_a_details = input("ğŸ“„ è¯·è¾“å…¥ Offer A çš„å…³é”®ä¿¡æ¯ (ä¾‹å¦‚ï¼šå…¬å¸åã€èŒä½ã€è–ªèµ„ã€åœ°ç‚¹ã€ä¼˜ç‚¹ã€é¡¾è™‘ç­‰):\n")
    offer_b_details = input("\nğŸ“„ è¯·è¾“å…¥ Offer B çš„å…³é”®ä¿¡æ¯ (åŒæ ·ï¼ŒåŒ…æ‹¬å…¬å¸åã€èŒä½ã€è–ªèµ„ã€åœ°ç‚¹ã€ä¼˜ç‚¹ã€é¡¾è™‘ç­‰):\n")

    print("\n[AIæ­£åœ¨ä¸ºæ‚¨ç”Ÿæˆå¯¹æ¯”åˆ†ææŠ¥å‘Šï¼Œè¯·ç¨å€™...]")

    prompt_text = f"""You are an expert career advisor. Your task is to conduct a structured analysis of two job offers for a user.

    Offer A Details: {offer_a_details}
    Offer B Details: {offer_b_details}

    Please perform the following steps:
    1.  **Create a Comparison Table**: Generate a clear markdown table comparing the two offers side-by-side. Key comparison dimensions should include (but are not limited to): Company, Position, Salary/Compensation, Location, Career Growth Potential, and Work-Life Balance.
    2.  **Pros and Cons Analysis**: For each offer, list its main advantages (Pros) and disadvantages (Cons) based on the user's input and general career knowledge.
    3.  **Recommendation and Key Questions**: Provide a concluding recommendation. Do not make a definitive choice for the user, but suggest which offer might be more suitable based on different priorities (e.g., "If you prioritize immediate financial return, Offer A seems better, but if long-term growth is your goal, Offer B has more potential."). Finally, pose 1-2 key questions to help the user make their final decision.

    Structure your entire response in clear, easy-to-read markdown.
    """
    prompt = ChatPromptTemplate.from_messages([("human", prompt_text)])
    chain = prompt | llm
    response = chain.invoke({})
    print_formatted(response.content)
    input("\nåˆ†æå·²å®Œæˆã€‚æŒ‰Enteré”®è¿”å›ä¸»èœå•...")


# --- Mode 3: Family Communication Simulation ---
def run_communication_simulation_mode(llm):
    """Simulates a conversation with a family member about career choices."""
    print("\n" + "â”€" * 80)
    print("                              æ¨¡å¼ä¸‰ï¼šå®¶åº­æ²Ÿé€šæ¨¡æ‹Ÿ")
    print("â”€" * 80)
    print_formatted(
        "ä½ å¥½ï¼å’Œå®¶äººæ²Ÿé€šèŒä¸šè§„åˆ’æœ‰æ—¶ä¼šé‡åˆ°å›°éš¾ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘å¯ä»¥æ‰®æ¼”ä½ çš„å®¶äººï¼ˆæ¯”å¦‚çˆ¶äº²æˆ–æ¯äº²ï¼‰ï¼Œä½ å¯ä»¥å®‰å…¨åœ°ç»ƒä¹ å¦‚ä½•è¡¨è¾¾è‡ªå·±çš„æƒ³æ³•ï¼Œå¹¶åº”å¯¹å¯èƒ½å‡ºç°çš„æ‹…å¿§å’Œé—®é¢˜ã€‚")

    my_choice = input("ğŸ—£ï¸ é¦–å…ˆï¼Œè¯·å‘Šè¯‰æˆ‘ä½ æƒ³è¦å’Œå®¶äººæ²Ÿé€šçš„èŒä¸šé€‰æ‹©æ˜¯ä»€ä¹ˆï¼Ÿ\n")
    family_concern = input("\nğŸ¤” ä½ è®¤ä¸ºä»–ä»¬ä¸»è¦çš„æ‹…å¿§ä¼šæ˜¯ä»€ä¹ˆï¼Ÿ(ä¾‹å¦‚ï¼šå·¥ä½œä¸ç¨³å®šã€ä¸æ˜¯é“é¥­ç¢—ã€ç¦»å®¶å¤ªè¿œç­‰)\n")

    meta_prompt = f"""You are an AI role-playing as a user's parent. The user wants to practice a difficult conversation about their career choice.

    **Your Persona**: You are a loving but concerned parent. Your primary concerns stem from what the user has described: '{family_concern}'. You want the best for your child, which to you means stability, security, and a respectable career path. You are skeptical of new or unconventional choices.

    **Your Task**:
    1.  Start the conversation from the parent's perspective, expressing your concern based on what you know.
    2.  Listen to the user's responses and react naturally. If they make a good point, you can be partially convinced but still raise other questions. If they are purely emotional, express your worry more strongly.
    3.  Your goal is NOT to be convinced easily. The goal is to provide a realistic simulation to help the user practice.
    4.  Keep your responses concise and in character.

    Let's begin the simulation. You will speak first.
    """

    store = {}

    def get_session_history(session_id: str) -> ChatMessageHistory:
        if session_id not in store:
            store[session_id] = ChatMessageHistory()
            # Start the conversation with the AI's (parent's) first line
            initial_ai_response = llm.invoke(meta_prompt)
            store[session_id].add_ai_message(initial_ai_response.content)
        return store[session_id]

    # Initialize the session and get the first message
    get_session_history("sim_session")
    initial_message = store["sim_session"].messages[0].content
    print_formatted(initial_message, prefix="AI (æ‰®æ¼”å®¶é•¿):")

    prompt = ChatPromptTemplate.from_messages([
        ("system", meta_prompt),
        MessagesPlaceholder(variable_name="history"),
        ("human", "{input}"),
    ])
    chain = RunnableWithMessageHistory(prompt | llm, get_session_history, input_messages_key="input",
                                       history_messages_key="history")

    while True:
        user_input = input("ä½ çš„å›åº”: ")
        if user_input.lower() in ['quit', 'exit']:
            print_formatted("å¥½çš„ï¼Œæ¨¡æ‹Ÿç»“æŸã€‚æ­£åœ¨è¿”å›ä¸»èœå•...")
            break

        print("\n[AI(å®¶é•¿)æ­£åœ¨æ€è€ƒå¦‚ä½•å›åº”...]")
        response = chain.invoke({"input": user_input}, config={"configurable": {"session_id": "sim_session"}})
        print_formatted(response.content, prefix="AI (æ‰®æ¼”å®¶é•¿):")


# --- Mode 4: Company Info Quick Look ---
def run_company_info_mode(llm):
    """Simulates scraping and summarizing company information."""
    print("\n" + "â”€" * 80)
    print("                               æ¨¡å¼å››ï¼šä¼ä¸šä¿¡æ¯é€Ÿè§ˆ")
    print("â”€" * 80)
    print_formatted("ä½ å¥½ï¼æƒ³å¿«é€Ÿäº†è§£ä¸€ä¸ªå…¬å¸å—ï¼Ÿè¯·è¾“å…¥å…¬å¸å…¨åï¼Œæˆ‘å°†æ¨¡æ‹ŸæŠ“å–å¹¶ä¸ºä½ ç”Ÿæˆä¸€ä»½æ ¸å¿ƒä¿¡æ¯é€Ÿè§ˆæŠ¥å‘Šã€‚")

    company_name = input("ğŸ¢ è¯·è¾“å…¥å…¬å¸åç§°:\n")

    print(f"\n[æ­£åœ¨æ¨¡æ‹ŸæŠ“å– {company_name} çš„ç›¸å…³ä¿¡æ¯å¹¶ç”ŸæˆæŠ¥å‘Š...]")

    prompt_text = f"""You are a professional business analyst AI. Your task is to generate a concise, structured summary of a company based on its name.

    Company Name: {company_name}

    Simulate that you have scraped the company's official website, recent news, and recruitment portals. Generate a report in clear markdown format that includes the following sections:

    1.  **å…¬å¸ç®€ä»‹ (Company Profile)**: A brief overview of the company, its mission, and its industry positioning.
    2.  **æ ¸å¿ƒäº§å“/ä¸šåŠ¡ (Core Products/Business)**: A list or description of its main products, services, or business units.
    3.  **è¿‘æœŸåŠ¨æ€ (Recent Developments)**: Summarize 2-3 recent significant news items, product launches, or strategic shifts.
    4.  **çƒ­æ‹›å²—ä½æ–¹å‘ (Hot Recruitment Areas)**: Based on simulated recruitment data, list 3-5 key types of positions the company is likely hiring for (e.g., "åç«¯å¼€å‘å·¥ç¨‹å¸ˆ", "äº§å“ç»ç†-AIæ–¹å‘", "å¸‚åœºè¥é”€ä¸“å‘˜").

    The information should be plausible and well-structured.
    """

    prompt = ChatPromptTemplate.from_messages([("human", prompt_text)])
    chain = prompt | llm
    response = chain.invoke({})
    print_formatted(response.content)
    input("\næŠ¥å‘Šå·²ç”Ÿæˆã€‚æŒ‰Enteré”®è¿”å›ä¸»èœå•...")


# --- Main Application ---
if __name__ == "__main__":
    print("AIèŒä¸šè§„åˆ’åŠ©æ‰‹åŸå‹å¯åŠ¨ (ä½¿ç”¨ç«å±±æ–¹èˆŸDeepSeekæ¨¡å‹)...")

    llm_instance = get_llm_instance()

    if llm_instance:
        while True:
            print("\n" + "=" * 35 + " ä¸»èœå• " + "=" * 35)
            print("è¯·é€‰æ‹©éœ€è¦ä½¿ç”¨çš„åŠŸèƒ½æ¨¡å¼ï¼š\n")
            print("  1. èŒä¸šç›®æ ‡æ¢ç´¢ (é€šè¿‡æ·±åº¦å¯¹è¯ï¼Œè¿›è¡Œè‡ªæˆ‘åˆ†æä¸è§„åˆ’)")
            print("  2. Offerå†³ç­–åˆ†æ (è¾“å…¥å¤šä¸ªOfferï¼Œè·å–ç»“æ„åŒ–å¯¹æ¯”å»ºè®®)")
            print("  3. å®¶åº­æ²Ÿé€šæ¨¡æ‹Ÿ (æ‰®æ¼”å®¶äººè§’è‰²ï¼Œç»ƒä¹ èŒä¸šé€‰æ‹©çš„æ²Ÿé€š)")
            print("  4. ä¼ä¸šä¿¡æ¯é€Ÿè§ˆ (è¾“å…¥å…¬å¸åï¼Œå¿«é€Ÿäº†è§£æ ¸å¿ƒæƒ…å†µ)")
            print("\n  0. é€€å‡ºç¨‹åº")
            print("=" * 80)

            choice = input("\nè¯·è¾“å…¥é€‰é¡¹ (0-4): ")

            if choice == '1':
                run_exploration_mode(llm_instance)
            elif choice == '2':
                run_decision_support_mode(llm_instance)
            elif choice == '3':
                run_communication_simulation_mode(llm_instance)
            elif choice == '4':
                run_company_info_mode(llm_instance)
            elif choice == '0':
                print_formatted("æ„Ÿè°¢ä½¿ç”¨ï¼Œå†è§ï¼")
                break
            else:
                print("æ— æ•ˆè¾“å…¥ï¼Œè¯·è¾“å…¥ 0 åˆ° 4 ä¹‹é—´çš„æ•°å­—ã€‚")

            time.sleep(1)  # A brief pause before showing the menu again
