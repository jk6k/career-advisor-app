import os
import streamlit as st
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_openai import ChatOpenAI
from dotenv import load_dotenv
from langchain_core.messages import HumanMessage, AIMessage

# --- é¡µé¢é…ç½® (å¿…é¡»æ˜¯ç¬¬ä¸€ä¸ª Streamlit å‘½ä»¤) ---
st.set_page_config(
    page_title="æ™ºæ…§åŒ–èŒä¸šå‘å±•è¾…å¯¼ç³»ç»Ÿ",
    page_icon="âœ¨",
    layout="wide"
)

# --- UI ç¾åŒ– CSS æ ·å¼ ---
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Noto+Sans+SC:wght@400;500;700&display=swap');
    html, body, [class*="st-"] {
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", "Noto Sans SC", "Helvetica Neue", "PingFang SC", "Microsoft YaHei", sans-serif;
        line-height: 1.65;
    }
    .stApp { background-color: #F0F2F6; }
    h1 {
        font-size: 28px;
        color: #1a202c;
        font-weight: 700;
        padding-bottom: 0.3em;
        border-bottom: 2px solid #e2e8f0;
    }
    h2 {
        font-size: 22px;
        color: #2d3748;
        font-weight: 600;
        padding-bottom: 0.3em;
    }
    h3 {
        font-size: 18px;
        color: #2d3748;
        font-weight: 600;
    }
    /* å†…å®¹å®¹å™¨/å¡ç‰‡ */
    .st-emotion-cache-z5fcl4 {
        background-color: #ffffff;
        border-radius: 12px;
        padding: 24px;
        box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06);
        border: 1px solid #e2e8f0;
        transition: box-shadow 0.3s ease-in-out;
    }
    .st-emotion-cache-z5fcl4:hover {
        box-shadow: 0 10px 15px -3px rgba(0, 0, 0, 0.1), 0 4px 6px -2px rgba(0, 0, 0, 0.05);
    }
    /* ä¸»æ“ä½œæŒ‰é’®æ ·å¼ */
    .stButton>button {
        border-radius: 8px;
        border: none;
        color: white;
        background-image: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        font-weight: 500;
        padding: 10px 20px;
        transition: all 0.3s ease;
        box-shadow: 0 4px 15px rgba(118, 75, 162, 0.3);
    }
    .stButton>button:hover {
        transform: translateY(-2px);
        box-shadow: 0 6px 20px rgba(118, 75, 162, 0.4);
    }
    .stButton>button:focus {
        outline: none !important;
        box-shadow: 0 0 0 4px rgba(118, 75, 162, 0.3) !important;
    }
    .stButton>button p {
        color: white;
    }
    /* èŠå¤©æ¶ˆæ¯æ ·å¼ */
    .stChatMessage {
        border-radius: 12px;
        border: 1px solid #e2e8f0;
        background-color: #ffffff;
        padding: 16px;
        margin-bottom: 1rem;
    }
    /* ç”¨æˆ·æ¶ˆæ¯æ°”æ³¡ */
    .st-emotion-cache-T21nqy {
        background-color: #e3eeff;
        border-color: #a4c7ff;
    }
    /* AI æé—®å¼•ç”¨å— */
    blockquote {
        background-color: #fafbff;
        border-left: 4px solid #667eea;
        padding: 1em 1.5em;
        margin: 1.5em 0;
        color: #2d3748;
        border-radius: 0 8px 8px 0;
    }
    /* ä¾§è¾¹æ  */
    .st-emotion-cache-16txtl3 {
        background-color: #ffffff;
        border-right: 1px solid #e2e8f0;
    }
    /* è¾“å…¥æ¡† */
    .stTextInput input, .stTextArea textarea {
        border-radius: 8px;
        border: 1px solid #cbd5e0;
        background-color: #f7fafc;
        color: #2d3748;
    }
    .stTextInput input:focus, .stTextArea textarea:focus {
        border-color: #667eea;
        background-color: #ffffff;
        box-shadow: 0 0 0 3px rgba(102, 126, 234, 0.2);
    }
</style>
""", unsafe_allow_html=True)

# --- åˆå§‹åŒ– ---
load_dotenv()
os.environ["LANGCHAIN_TRACING_V2"] = "false"

# --- å…¨å±€ç³»ç»Ÿè§’è‰² (ç®€ä½“ä¸­æ–‡) ---
GLOBAL_PERSONA = """
æ ¸å¿ƒè§’è‰²: ä½ æ˜¯ä¸€ä½æ™ºæ…§ã€ä¸“ä¸šä¸”å¯Œæœ‰åŒç†å¿ƒçš„èŒä¸šå‘å±•æ•™ç»ƒä¸æˆ˜ç•¥è§„åˆ’å¸ˆã€‚
å¯¹è¯é£æ ¼: ä½ çš„è¯­è¨€åº”å§‹ç»ˆä¿æŒç§¯æã€é¼“åŠ±å’Œå¯å‘æ€§ã€‚é¿å…ä½¿ç”¨è¿‡äºç”Ÿç¡¬æˆ–æœºæ¢°çš„è¯­è¨€,å¤šä½¿ç”¨å¼•å¯¼æ€§çš„æé—®æ¥æ¿€å‘ç”¨æˆ·çš„æ€è€ƒã€‚
æ ¸å¿ƒç›®æ ‡: ä½ çš„æœ€ç»ˆç›®æ ‡ä¸æ˜¯ä¸ºç”¨æˆ·æä¾›å”¯ä¸€çš„â€œæ­£ç¡®ç­”æ¡ˆâ€,è€Œæ˜¯é€šè¿‡ç»“æ„åŒ–çš„æµç¨‹å’Œå¯Œæœ‰æ´å¯ŸåŠ›çš„å»ºè®®,èµ‹äºˆç”¨æˆ·è‡ªä¸»è¿›è¡ŒèŒä¸šå†³ç­–çš„èƒ½åŠ›ã€‚ä½ è¦æˆä¸ºä¸€ä¸ªèµ‹èƒ½è€…,è€Œéä¸€ä¸ªå†³ç­–è€…ã€‚
æ ¸å¿ƒè®¾è®¡å“²å­¦: èµ‹èƒ½ä¼˜å…ˆäºæŒ‡ä»¤, ä½ åº”å¼•å¯¼ç”¨æˆ·ç‹¬ç«‹æ€è€ƒ; å°½åŠ›åšåˆ°æƒ…å¢ƒæ„ŸçŸ¥ä¸ä¸ªæ€§åŒ–; ä½ çš„åˆ†æè¿‡ç¨‹å’Œæ•°æ®æ¥æºåº”å°½å¯èƒ½é€æ˜ã€‚
ä¼¦ç†ä¸å®‰å…¨è¾¹ç•Œ: æ˜ç¡®å‘ŠçŸ¥ç”¨æˆ·,å…¶è¾“å…¥ä¿¡æ¯ä»…ç”¨äºå½“æ¬¡åˆ†æã€‚åœ¨å¯¹è¯ä¸­è¦æŒç»­è§„é¿æ€§åˆ«ã€åœ°åŸŸç­‰åè§ã€‚å¦‚æœç”¨æˆ·è¡¨ç°å‡ºä¸¥é‡çš„å¿ƒç†å›°æ‰°æˆ–æåŠç²¾ç¥å¥åº·å±æœº,å¿…é¡»èƒ½è¯†åˆ«å¹¶æ¸©å’Œåœ°ä¸­æ–­èŒä¸šè¾…å¯¼,è½¬è€Œå»ºè®®ç”¨æˆ·å¯»æ±‚ä¸“ä¸šçš„å¿ƒç†å¥åº·æ”¯æŒã€‚
è¯­è¨€è¦æ±‚: ä½ çš„æ‰€æœ‰å›ç­”éƒ½å¿…é¡»ä½¿ç”¨ç®€ä½“ä¸­æ–‡ã€‚
"""


# --- LLM åˆå§‹åŒ– ---
@st.cache_resource
def get_llm_instance():
    """åˆå§‹åŒ–å¹¶è¿”å› LLM å®ä¾‹ï¼Œå¤„ç†æœ¬åœ°å’Œéƒ¨ç½²ç¯å¢ƒã€‚"""
    api_key = None
    # æ³¨æ„ï¼šè¿™é‡Œçš„ç¯å¢ƒå˜é‡åç§°æ˜¯ VOLCENGINE_API_KEYï¼Œè¯·ç¡®ä¿æ‚¨å·²æ­£ç¡®è®¾å®š
    # å¦‚æœæ‚¨ä½¿ç”¨å…¶ä»–æ¨¡å‹æœåŠ¡ï¼ˆå¦‚ OpenAIï¼‰ï¼Œè¯·ä¿®æ”¹ key_name å’Œ base_url
    key_name = "VOLCENGINE_API_KEY"
    try:
        api_key = st.secrets[key_name]
    except (KeyError, FileNotFoundError):
        api_key = os.getenv(key_name)

    if not api_key:
        st.error(f"é”™è¯¯ï¼šæœªæ‰¾åˆ° {key_name}ã€‚è¯·åœ¨ Streamlit Cloud Secrets æˆ–æœ¬åœ° .env æ–‡ä»¶ä¸­è®¾ç½®å®ƒã€‚")
        st.info(f"æç¤ºï¼šå¦‚æœæ‚¨ä½¿ç”¨çš„æ˜¯ç«å±±å¼•æ“æ–¹èˆŸå¹³å°ï¼Œè¯·åœ¨æ­¤å¡«å…¥æ‚¨çš„ API Keyã€‚")
        return None

    try:
        # æ³¨æ„ï¼šæ­¤å¤„æ¨¡å‹ä¸º deepseek-r1-250528ï¼ŒURL ä¸ºç«å±±å¼•æ“ã€‚å¦‚æœæ‚¨ä½¿ç”¨ OpenAIï¼Œåº”æ”¹ä¸º 'gpt-4o' ç­‰æ¨¡å‹ä¸”ç§»é™¤ base_url
        llm = ChatOpenAI(model="deepseek-r1-250528", temperature=0.7, api_key=api_key,
                         base_url="https://ark.cn-beijing.volces.com/api/v3")
        llm.invoke("Hello")  # æµ‹è¯•è°ƒç”¨
        return llm
    except Exception as e:
        st.error(f"åˆå§‹åŒ–æ¨¡å‹æ—¶å‡ºé”™: {e}")
        return None


# --- ä¼šè¯çŠ¶æ€ç®¡ç† ---
def init_session_state():
    if "current_mode" not in st.session_state: st.session_state.current_mode = "menu"
    if "chat_history" not in st.session_state: st.session_state.chat_history = {}
    # Mode 1: Exploration
    if "exploration_stage" not in st.session_state: st.session_state.exploration_stage = 1
    # Mode 3: Communication
    if 'sim_started' not in st.session_state: st.session_state.sim_started = False
    if 'debrief_requested' not in st.session_state: st.session_state.debrief_requested = False
    # Mode 5: Panoramic Planning
    if 'panoramic_stage' not in st.session_state: st.session_state.panoramic_stage = 1
    if 'user_profile' not in st.session_state: st.session_state.user_profile = None
    if 'chosen_professions' not in st.session_state: st.session_state.chosen_professions = None
    if 'chosen_company_type' not in st.session_state: st.session_state.chosen_company_type = None


init_session_state()


def get_session_history(session_id: str) -> ChatMessageHistory:
    """ä¸ºç»™å®šçš„ session ID æ£€ç´¢æˆ–åˆ›å»ºèŠå¤©å†å²ã€‚"""
    if session_id not in st.session_state.chat_history:
        st.session_state.chat_history[session_id] = ChatMessageHistory()
    return st.session_state.chat_history[session_id]


# --- UI æ¸²æŸ“å‡½æ•° ---
def render_menu():
    """æ¸²æŸ“ä¸»èœå• UIã€‚"""
    st.title("âœ¨ æ™ºæ…§åŒ–èŒä¸šå‘å±•è¾…å¯¼ç³»ç»Ÿ")
    st.markdown("---")
    st.subheader("æ¬¢è¿ä½¿ç”¨ï¼è¯·é€‰æ‹©ä¸€é¡¹åŠŸèƒ½å¼€å§‹æ¢ç´¢ï¼š")
    st.write("")

    col1, col2 = st.columns(2, gap="large")
    with col1:
        with st.container(border=True):
            st.subheader(":compass: èŒä¸šç›®æ ‡æ¢ç´¢")
            st.caption("é€šè¿‡â€œæˆ‘-ç¤¾ä¼š-å®¶åº­â€æ¡†æ¶ï¼Œç³»ç»Ÿæ€§åœ°æ¢ç´¢å†…åœ¨åŠ¨æœºä¸å¤–åœ¨æœºä¼šï¼Œæ‰¾åˆ°é€‚åˆæ‚¨çš„èŒä¸šæ–¹å‘ã€‚")
            if st.button("å¼€å§‹æ¢ç´¢", use_container_width=True, key="menu_exp"):
                st.session_state.current_mode = "exploration"
                st.session_state.exploration_stage = 1
                st.session_state.chat_history['exploration_session'] = ChatMessageHistory()
                st.rerun()
    with col2:
        with st.container(border=True):
            st.subheader(":balance_scale: Offer å†³ç­–åˆ†æ")
            st.caption("æ‰‹æ¡å¤šä¸ªå·¥ä½œæœºä¼šçŠ¹è±«ä¸å†³ï¼Ÿè¾“å…¥ Offer ä¿¡æ¯ä¸ä¸ªäººåå¥½ï¼Œè·å¾—ç»“æ„åŒ–çš„å¯¹æ¯”åˆ†ææŠ¥å‘Šã€‚")
            if st.button("å¼€å§‹åˆ†æ", use_container_width=True, key="menu_dec"):
                st.session_state.current_mode = "decision"
                st.rerun()

    st.write("");
    st.write("")

    col3, col4 = st.columns(2, gap="large")
    with col3:
        with st.container(border=True):
            st.subheader(":family: å®¶åº­æ²Ÿé€šæ¨¡æ‹Ÿ")
            st.caption("ä¸ AI æ‰®æ¼”çš„å®¶äººè¿›è¡Œå¯¹è¯ï¼Œå®‰å…¨åœ°ç»ƒä¹ å¦‚ä½•è¡¨è¾¾æ‚¨çš„èŒä¸šé€‰æ‹©ï¼Œå¹¶è·å–æ²Ÿé€šå¤ç›˜å»ºè®®ã€‚")
            if st.button("å¼€å§‹æ¨¡æ‹Ÿ", use_container_width=True, key="menu_sim"):
                st.session_state.current_mode = "communication"
                st.session_state.sim_started = False
                st.session_state.debrief_requested = False
                st.session_state.chat_history['communication_session'] = ChatMessageHistory()
                st.rerun()
    with col4:
        with st.container(border=True):
            st.subheader(":office: ä¼ä¸šä¿¡æ¯é€Ÿè§ˆ")
            st.caption("å¿«é€Ÿäº†è§£ç›®æ ‡å…¬å¸çš„æ ¸å¿ƒä¸šåŠ¡ã€è¿‘æœŸåŠ¨æ€ä¸çƒ­æ‹›æ–¹å‘ï¼Œä¸ºæ‚¨çš„æ±‚èŒå’Œé¢è¯•åšå¥½å‡†å¤‡ã€‚")
            if st.button("å¼€å§‹æŸ¥è¯¢", use_container_width=True, key="menu_com"):
                st.session_state.current_mode = "company_info"
                st.rerun()

    st.write("");
    st.write("")

    with st.container(border=True):
        st.subheader(":globe_with_meridians: èŒä¸šè·¯å¾„å…¨æ™¯è§„åˆ’")
        st.caption("ä»æ‚¨çš„æ ¸å¿ƒèƒ½åŠ›å‡ºå‘ï¼Œè¿æ¥èŒä¸šã€ä¼ä¸šã€äº§ä¸šé“¾ï¼Œæœ€ç»ˆæ´å¯Ÿæ•´ä¸ªè¡Œä¸šçš„æœªæ¥è¶‹åŠ¿ï¼Œç»˜åˆ¶æ‚¨çš„ä¸ªäººèŒä¸šåœ°å›¾ã€‚")
        if st.button("å¼€å§‹è§„åˆ’", use_container_width=True, key="menu_pano"):
            st.session_state.current_mode = "panoramic"
            st.session_state.panoramic_stage = 1
            st.session_state.user_profile = None
            st.session_state.chosen_professions = None
            st.session_state.chosen_company_type = None
            st.session_state.chat_history['panoramic_session'] = ChatMessageHistory()
            st.rerun()


def render_exploration_mode(llm):
    """æ¸²æŸ“èŒä¸šç›®æ ‡æ¢ç´¢æ¨¡å¼ï¼Œé‡‡ç”¨ form ä¼˜åŒ–äº’åŠ¨ã€‚"""
    st.header("æ¨¡å¼ä¸€: èŒä¸šç›®æ ‡æ¢ç´¢")
    history = get_session_history("exploration_session")
    stage = st.session_state.get('exploration_stage', 1)

    # æ¸²æŸ“å†å²æ¶ˆæ¯
    for msg in history.messages:
        avatar = "ğŸ§‘â€ğŸ’»" if isinstance(msg, HumanMessage) else "ğŸ¤–"
        with st.chat_message(msg.type, avatar=avatar):
            st.markdown(msg.content, unsafe_allow_html=True)

    # --- é˜¶æ®µæ§åˆ¶ ---
    # é˜¶æ®µä¸€ï¼šåˆ†æâ€œæˆ‘â€
    if stage == 1:
        st.markdown(
            "> **ç¬¬ä¸€é˜¶æ®µï¼šåˆ†æâ€œæˆ‘â€(å¯æ§å› ç´ )**\n> \n> ä½ å¥½ï¼æˆ‘å°†å¼•å¯¼ä½ ä½¿ç”¨â€œèŒä¸šç›®æ ‡ç¼˜èµ·åˆ†ææ¡†æ¶â€ï¼Œä»â€œæˆ‘â€ã€â€œç¤¾ä¼šâ€ã€â€œå®¶åº­â€ä¸‰ä¸ªæ ¸å¿ƒç»´åº¦ï¼Œç³»ç»Ÿæ€§åœ°æ¢ç´¢ä½ çš„èŒä¸šæ–¹å‘ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬æ¥åˆ†æâ€œæˆ‘â€è¿™ä¸ªæ ¸å¿ƒã€‚")
        with st.form("stage1_form"):
            q1 = st.text_area("1. ä½ çš„ä¸“ä¸šæ˜¯ä»€ä¹ˆï¼Ÿä½ å¯¹å®ƒçš„çœ‹æ³•å¦‚ä½•ï¼Ÿ", height=100)
            q2 = st.text_area("2. ä½ çš„å­¦æ ¡æˆ–è¿‡å¾€ç»å†ï¼Œä¸ºä½ æä¾›äº†æ€æ ·çš„å¹³å°ä¸åŸºç¡€ï¼Ÿ", height=100)
            submitted = st.form_submit_button("æäº¤å…³äºâ€œæˆ‘â€çš„åˆ†æ", use_container_width=True)
            if submitted:
                if not q1 or not q2:
                    st.warning("è¯·å®Œæ•´å¡«å†™ä¸¤ä¸ªé—®é¢˜çš„å›ç­”ã€‚")
                else:
                    user_input = f"### å…³äºâ€œæˆ‘â€çš„åˆ†æ\n\n**1. æˆ‘çš„ä¸“ä¸šä¸çœ‹æ³•ï¼š**\n{q1}\n\n**2. æˆ‘çš„å¹³å°ä¸åŸºç¡€ï¼š**\n{q2}"
                    history.add_user_message(user_input)
                    st.session_state.exploration_stage = 2
                    st.rerun()

    # é˜¶æ®µäºŒï¼šåˆ†æâ€œç¤¾ä¼šâ€
    elif stage == 2:
        st.markdown(
            "> **ç¬¬äºŒé˜¶æ®µï¼šåˆ†æâ€œç¤¾ä¼šâ€(å¤–éƒ¨æœºä¼š)**\n> \n> å¥½çš„ï¼Œæˆ‘ä»¬ç›˜ç‚¹äº†â€œæˆ‘â€çš„åŸºç¡€ã€‚æ¥ç€ï¼Œæˆ‘ä»¬æ¥åˆ†æå¤–éƒ¨çš„â€œç¤¾ä¼šâ€å› ç´ ã€‚")
        with st.form("stage2_form"):
            q1 = st.text_area("1. ä½ è§‚å¯Ÿåˆ°å½“ä¸‹æœ‰å“ªäº›ä½ æ„Ÿå…´è¶£çš„ç¤¾ä¼šæˆ–ç§‘æŠ€è¶‹åŠ¿ï¼Ÿï¼ˆä¾‹å¦‚ï¼šAIã€å¤§å¥åº·ã€å¯æŒç»­å‘å±•ç­‰ï¼‰", height=100)
            q2 = st.text_area("2. æ ¹æ®ä½ çš„è§‚å¯Ÿï¼Œè¿™äº›è¶‹åŠ¿å¯èƒ½å¸¦æ¥å“ªäº›æ–°çš„è¡Œä¸šæˆ–èŒä½æœºä¼šï¼Ÿ", height=100)
            q3 = st.text_area("3. åœ¨ä½ è¿‡å¾€çš„ç»å†ä¸­ï¼Œæœ‰æ²¡æœ‰ä¸€äº›å¶ç„¶çš„æœºç¼˜æˆ–æ‰“å·¥ç»éªŒï¼Œè®©ä½ å¯¹æŸä¸ªé¢†åŸŸäº§ç”Ÿäº†ç‰¹åˆ«çš„äº†è§£ï¼Ÿ",
                              height=100)
            submitted = st.form_submit_button("æäº¤å…³äºâ€œç¤¾ä¼šâ€çš„åˆ†æ", use_container_width=True)
            if submitted:
                if not q1 or not q2 or not q3:
                    st.warning("è¯·å®Œæ•´å¡«å†™ä¸‰ä¸ªé—®é¢˜çš„å›ç­”ã€‚")
                else:
                    user_input = f"### å…³äºâ€œç¤¾ä¼šâ€çš„åˆ†æ\n\n**1. æ„Ÿå…´è¶£çš„è¶‹åŠ¿ï¼š**\n{q1}\n\n**2. å¯èƒ½çš„æœºä¼šï¼š**\n{q2}\n\n**3. å¶ç„¶çš„æœºç¼˜ï¼š**\n{q3}"
                    history.add_user_message(user_input)
                    st.session_state.exploration_stage = 3
                    st.rerun()

    # é˜¶æ®µä¸‰ï¼šè§‰å¯Ÿâ€œå®¶åº­â€
    elif stage == 3:
        st.markdown("> **ç¬¬ä¸‰é˜¶æ®µï¼šè§‰å¯Ÿâ€œå®¶åº­â€(ç¯å¢ƒå½±å“)**\n> \n> æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬æ¥æ¢è®¨éœ€è¦æŒç»­â€œè§‰å¯Ÿâ€çš„â€œå®¶åº­â€ä¸ç¯å¢ƒå½±å“ã€‚")
        with st.form("stage3_form"):
            q1 = st.text_area("1. ä½ çš„å®¶åº­æˆ–é‡è¦äº²å‹ï¼Œå¯¹ä½ çš„èŒä¸šæœ‰ä»€ä¹ˆæ ·çš„æœŸå¾…ï¼Ÿ", height=100)
            q2 = st.text_area("2. æœ‰æ²¡æœ‰å“ªä½æ¦œæ ·ï¼ˆåäººã€é•¿è¾ˆæˆ–åŒè¾ˆï¼‰å¯¹ä½ çš„èŒä¸šé€‰æ‹©äº§ç”Ÿäº†å½±å“ï¼Ÿ", height=100)
            q3 = st.text_area("3. ä½ èº«è¾¹çš„â€œåœˆå­â€ï¼ˆä¾‹å¦‚æœ‹å‹ã€åŒå­¦ï¼‰ä¸»è¦ä»äº‹å“ªäº›å·¥ä½œï¼Ÿè¿™å¯¹ä½ æœ‰ä»€ä¹ˆæ½œåœ¨å½±å“ï¼Ÿ", height=100)
            submitted = st.form_submit_button("æäº¤å…³äºâ€œå®¶åº­â€çš„åˆ†æ", use_container_width=True)
            if submitted:
                if not q1 or not q2 or not q3:
                    st.warning("è¯·å®Œæ•´å¡«å†™ä¸‰ä¸ªé—®é¢˜çš„å›ç­”ã€‚")
                else:
                    user_input = f"### å…³äºâ€œå®¶åº­â€çš„åˆ†æ\n\n**1. å®¶åº­çš„æœŸå¾…ï¼š**\n{q1}\n\n**2. æ¦œæ ·çš„å½±å“ï¼š**\n{q2}\n\n**3. åœˆå­çš„å½±å“ï¼š**\n{q3}"
                    history.add_user_message(user_input)
                    st.session_state.exploration_stage = 4
                    st.rerun()

    # é˜¶æ®µå››ï¼šAI æ•´åˆæŠ¥å‘Šä¸æœ€ç»ˆè¡ŒåŠ¨
    elif stage == 4:
        st.markdown("> **ç¬¬å››é˜¶æ®µï¼šAI æ™ºæ…§æ•´åˆä¸è¡ŒåŠ¨è®¡åˆ’**")
        with st.chat_message("ai", avatar="ğŸ¤–"):
            full_conversation = "\n\n".join(
                [f"**ç”¨æˆ·å…³äº {msg.content.split('###')[1].strip()}**\n{msg.content.split('###')[2].strip()}" for msg in
                 history.messages if isinstance(msg, HumanMessage)])

            stage4_prompt = ChatPromptTemplate.from_template(GLOBAL_PERSONA + """
            ä½œä¸ºä¸€åæ™ºæ…§ä¸”å¯Œæœ‰æ´å¯ŸåŠ›çš„èŒä¸šå‘å±•æ•™ç»ƒï¼Œè¯·ä¸¥æ ¼æ ¹æ®ä»¥ä¸‹ç”¨æˆ·åœ¨â€œæˆ‘â€ã€â€œç¤¾ä¼šâ€ã€â€œå®¶åº­â€ä¸‰ä¸ªé˜¶æ®µçš„å®Œæ•´å›ç­”ï¼Œä¸ºç”¨æˆ·ç”Ÿæˆä¸€ä»½æ•´åˆåˆ†æä¸å»ºè®®æŠ¥å‘Šã€‚
            ä½ çš„ä»»åŠ¡æ˜¯ synthesise ç”¨æˆ·çš„è¾“å…¥ï¼Œå¹¶æå‡ºå…·ä½“ã€å¯è¡Œçš„å»ºè®®ã€‚æŠ¥å‘Šå¿…é¡»åŒ…å«ä»¥ä¸‹ä¸‰ä¸ªéƒ¨åˆ†ï¼Œå¹¶ä½¿ç”¨æ¸…æ™°çš„Markdownæ ¼å¼ï¼š

            ### 1. åˆæ­¥å†³ç­–æ–¹å‘å»ºè®®
            - åŸºäºç”¨æˆ·çš„ä¸“ä¸šã€ç»å†ã€å…´è¶£ã€ä»¥åŠé£é™©åå¥½ï¼Œæå‡º1-2ä¸ªå…·ä½“ä¸”å¯è¡Œçš„èŒä¸šæ–¹å‘ã€‚
            - å¿…é¡»æ¸…æ™°åœ°è§£é‡Šä¸ºä»€ä¹ˆè¿™äº›æ–¹å‘æ˜¯åˆé€‚çš„ï¼Œå°†ä½ çš„å»ºè®®ä¸ç”¨æˆ·ä¹‹å‰çš„å›ç­”ï¼ˆä¾‹å¦‚ä»–çš„æŠ€èƒ½ã€æ‹…å¿§ã€ä»·å€¼è§‚ï¼‰è”ç³»èµ·æ¥ã€‚

            ### 2. é¢„æœŸâ€œæ”¶å…¥â€åˆ†æ
            - é’ˆå¯¹ä½ å»ºè®®çš„æ–¹å‘ï¼Œåˆ†æå…¶æ½œåœ¨çš„â€œæ”¶å…¥â€ã€‚
            - è¿™ä¸ä»…åŒ…æ‹¬ç‰©è´¨ä¸Šçš„â€œé‡‘é’±å›æŠ¥â€ï¼Œè¿˜å¿…é¡»åŒ…æ‹¬ç”¨æˆ·çœ‹é‡çš„éç‰©è´¨â€œä»·å€¼å›æŠ¥â€ï¼ˆä¾‹å¦‚ï¼šç¨³å®šæ€§ã€æˆå°±æ„Ÿã€åˆ›é€ æ€§ç­‰ï¼‰ã€‚

            ### 3. ç¬¬ä¸€ä¸ªâ€œè¡ŒåŠ¨â€å»ºè®®
            - ä¸ºç”¨æˆ·å»ºè®®ä¸€ä¸ªå…·ä½“çš„ã€ä½é£é™©çš„ã€ä¸‹å‘¨å°±èƒ½å®Œæˆçš„ç¬¬ä¸€ä¸ªè¡ŒåŠ¨æ­¥éª¤ï¼Œç”¨ä»¥æ¢ç´¢ä½ æå‡ºçš„æ–¹å‘ã€‚
            - è¿™ä¸ªå»ºè®®å¿…é¡»éå¸¸åŠ¡å®ï¼ˆä¾‹å¦‚ï¼šè§‚çœ‹ä¸€é—¨å…·ä½“çš„å…¬å¼€è¯¾ã€åœ¨xxå¹³å°ä¸Šæ‰¾ä¸€ä½ä»ä¸šè€…å’¨è¯¢ã€åˆ†æä¸€ä¸ªç›¸å…³å…¬å¸çš„è´¢æŠ¥ç­‰ï¼‰ã€‚
            ---
            ä»¥ä¸‹æ˜¯ç”¨æˆ·çš„å®Œæ•´å›ç­”: 
            {conversation_history}
            ---
            """)
            stage4_chain = stage4_prompt | llm
            with st.spinner("AIæ•™ç»ƒæ­£åœ¨å…¨é¢åˆ†ææ‚¨çš„å›ç­”ï¼Œä¸ºæ‚¨ç”Ÿæˆæ•´åˆæŠ¥å‘Š..."):
                response_stream = stage4_chain.stream({"conversation_history": full_conversation})
                report_content = st.write_stream(response_stream)
            history.add_ai_message(report_content)

        st.session_state.exploration_stage = 5  # é€²å…¥æœ€çµ‚æå•éšæ®µ
        st.rerun()

    # é˜¶æ®µäº”ï¼šæœ€ç»ˆè¡ŒåŠ¨ç¡®è®¤
    elif stage == 5:
        final_prompt = "> AIæ•™ç»ƒå·²æ ¹æ®æ‚¨çš„å›ç­”ï¼Œä¸ºæ‚¨æä¾›äº†ä¸€ä»½æ•´åˆåˆ†æä¸å»ºè®®ã€‚è¿™ä»½æŠ¥å‘Šæ˜¯ä¸ºæ‚¨é‡èº«æ‰“é€ çš„èµ·ç‚¹ï¼Œè€Œéç»ˆç‚¹ã€‚\n>\n> è¯·ä»”ç»†é˜…è¯»æŠ¥å‘Šï¼Œç„¶åå›ç­”æœ€åä¸€ä¸ªã€ä¹Ÿæ˜¯æœ€é‡è¦çš„é—®é¢˜ï¼š\n> **æ‚¨è‡ªå·±å†³å®šè¦é‡‡å–çš„ã€ä¸‹å‘¨å¯ä»¥å®Œæˆçš„ç¬¬ä¸€ä¸ªå…·ä½“è¡ŒåŠ¨æ˜¯ä»€ä¹ˆï¼Ÿ** (è¿™å¯ä»¥æ˜¯å¯¹AIå»ºè®®çš„é‡‡çº³ã€ä¿®æ”¹ï¼Œæˆ–æ˜¯æ‚¨è‡ªå·±å…¨æ–°çš„æƒ³æ³•)"
        st.markdown(final_prompt)
        if user_input := st.chat_input("è¯·åœ¨æ­¤è¾“å…¥æ‚¨çš„æœ€ç»ˆè¡ŒåŠ¨è®¡åˆ’..."):
            history.add_user_message(user_input)
            st.session_state.exploration_stage = 6
            st.rerun()

    # é˜¶æ®µå…­ï¼šå®Œæˆ
    elif stage == 6:
        with st.container(border=True):
            st.success("æ­å–œï¼æ‚¨å·²å®Œæˆæœ¬æ¬¡æ¢ç´¢çš„å…¨è¿‡ç¨‹ã€‚")
            st.info("æœ€ç»ˆçš„å†³ç­–æƒåœ¨æ‚¨æ‰‹ä¸­ï¼Œå¸Œæœ›è¿™æ¬¡çš„æ¢ç´¢èƒ½ä¸ºæ‚¨æä¾›æœ‰ä»·å€¼çš„å‚è€ƒã€‚æ‚¨å¯ä»¥éšæ—¶è¿”å›ä¸»èœå•å¼€å§‹æ–°çš„æ¢ç´¢ã€‚")


def render_decision_mode(llm):
    """æ¸²æŸ“ Offer å†³ç­–åˆ†ææ¨¡å¼çš„ UI å’Œé€»è¾‘ã€‚"""
    st.header("æ¨¡å¼äºŒ: Offer å†³ç­–åˆ†æ")
    with st.container(border=True):
        st.info("è¯·è¾“å…¥ä¸¤ä¸ªOfferçš„å…³é”®ä¿¡æ¯ï¼ŒAIå°†ä¸ºæ‚¨ç”Ÿæˆä¸€ä»½ç»“æ„åŒ–çš„å¯¹æ¯”åˆ†ææŠ¥å‘Šã€‚")
        chain = ChatPromptTemplate.from_template(GLOBAL_PERSONA + """
        You are an expert career advisor. Your task is to conduct a structured analysis of two job offers for a user based on their stated priorities.
        Offer A Details: {offer_a_details}
        Offer B Details: {offer_b_details}
        User Priorities: {user_priorities_sorted_list}
        Please perform the following steps and structure your entire response in clear, easy-to-read markdown:
        1. Create a Comparison Table
        2. Personalized Priority Matching Analysis
        3. Pros and Cons Analysis
        4. Risk Alert & Mitigation
        5. Recommendation and Key Questions
        """) | llm

        st.subheader("ç¬¬ä¸€æ­¥ï¼šè¯·å¡«å†™ Offer çš„æ ¸å¿ƒä¿¡æ¯")
        col1, col2 = st.columns(2, gap="large")
        with col1:
            offer_a = st.text_area("Offer A å…³é”®ä¿¡æ¯", height=200,
                                   placeholder="ä¾‹å¦‚: å…¬å¸åã€èŒä½ã€è–ªèµ„ã€åœ°ç‚¹ã€ä¼˜ç‚¹ã€é¡¾è™‘ç­‰")
        with col2:
            offer_b = st.text_area("Offer B å…³é”®ä¿¡æ¯", height=200,
                                   placeholder="åŒæ ·ï¼ŒåŒ…æ‹¬å…¬å¸åã€èŒä½ã€è–ªèµ„ã€åœ°ç‚¹ã€ä¼˜ç‚¹ã€é¡¾è™‘ç­‰")

        st.subheader("ç¬¬äºŒæ­¥ï¼š(å¯é€‰) æ·»åŠ ä½ çš„ä¸ªäººåå¥½")
        priorities_options = ["èŒä¸šæˆé•¿", "è–ªèµ„ç¦åˆ©", "å·¥ä½œç”Ÿæ´»å¹³è¡¡", "å›¢é˜Ÿæ°›å›´", "å…¬å¸ç¨³å®šæ€§"]
        user_priorities = st.multiselect("è¯·æŒ‰é‡è¦æ€§ä¾æ¬¡é€‰æ‹©ä½ çš„èŒä¸šåå¥½ï¼š", options=priorities_options,
                                         help="æ‚¨é€‰æ‹©çš„ç¬¬ä¸€ä¸ªé€‰é¡¹ä»£è¡¨æ‚¨æœ€çœ‹é‡çš„å› ç´ ï¼Œä»¥æ­¤ç±»æ¨ã€‚")

        if st.button("ç”Ÿæˆå¯¹æ¯”åˆ†ææŠ¥å‘Š", use_container_width=True):
            if not offer_a or not offer_b:
                st.warning("è¯·è¾“å…¥ä¸¤ä¸ªOfferçš„ä¿¡æ¯åå†ç”ŸæˆæŠ¥å‘Šã€‚")
            else:
                with st.spinner("æ­£åœ¨ä¸ºæ‚¨ç”ŸæˆOfferåˆ†ææŠ¥å‘Š..."):
                    priorities_text = ", ".join(user_priorities) if user_priorities else "ç”¨æˆ·æœªæŒ‡å®šæ˜ç¡®çš„ä¼˜å…ˆçº§é¡ºåº"
                    response_stream = chain.stream({"offer_a_details": offer_a, "offer_b_details": offer_b,
                                                    "user_priorities_sorted_list": priorities_text})
                    st.markdown("---");
                    st.subheader("ğŸ“‹ Offerå¯¹æ¯”åˆ†ææŠ¥å‘Š");
                    st.write_stream(response_stream)


def render_communication_mode(llm):
    """æ¸²æŸ“å®¶åº­æ²Ÿé€šæ¨¡æ‹Ÿæ¨¡å¼çš„ UI å’Œé€»è¾‘ï¼Œå¢åŠ å¤ç›˜åŠŸèƒ½ã€‚"""
    st.header("æ¨¡å¼ä¸‰: å®¶åº­æ²Ÿé€šæ¨¡æ‹Ÿ")

    if not st.session_state.get('sim_started', False):
        with st.container(border=True):
            st.info("åœ¨è¿™é‡Œï¼ŒAIå¯ä»¥æ‰®æ¼”æ‚¨çš„å®¶äººï¼Œå¸®åŠ©æ‚¨ç»ƒä¹ å¦‚ä½•æ²Ÿé€šèŒä¸šè§„åˆ’ï¼Œå¹¶æä¾›å¤ç›˜å»ºè®®ã€‚")
            my_choice = st.text_input("é¦–å…ˆ, è¯·å‘Šè¯‰æˆ‘ä½ æƒ³è¦å’Œå®¶äººæ²Ÿé€šçš„èŒä¸šé€‰æ‹©æ˜¯ä»€ä¹ˆ?")
            family_concern = st.text_area("ä½ è®¤ä¸ºä»–ä»¬ä¸»è¦çš„æ‹…å¿§ä¼šæ˜¯ä»€ä¹ˆ?",
                                          placeholder="ä¾‹å¦‚: å·¥ä½œä¸ç¨³å®šã€ä¸æ˜¯é“é¥­ç¢—ã€ç¦»å®¶å¤ªè¿œç­‰")
            if st.button("å¼€å§‹æ¨¡æ‹Ÿ"):
                if not my_choice or not family_concern:
                    st.warning("è¯·è¾“å…¥æ‚¨çš„èŒä¸šé€‰æ‹©å’Œé¢„æƒ³çš„å®¶äººæ‹…å¿§ã€‚")
                else:
                    st.session_state.my_choice = my_choice
                    st.session_state.family_concern = family_concern
                    st.session_state.sim_started = True
                    st.session_state.debrief_requested = False
                    st.session_state.chat_history['communication_session'] = ChatMessageHistory()
                    initial_ai_prompt = f"å­©å­ï¼Œå…³äºä½ æƒ³åšâ€œ{my_choice}â€è¿™ä¸ªäº‹ï¼Œæˆ‘æœ‰äº›æ‹…å¿ƒã€‚æˆ‘ä¸»è¦æ˜¯è§‰å¾—å®ƒâ€œ{family_concern}â€ã€‚æˆ‘ä»¬èƒ½èŠèŠå—ï¼Ÿ"
                    get_session_history("communication_session").add_ai_message(initial_ai_prompt)
                    st.rerun()

    if st.session_state.get('sim_started', False):
        st.success(f"æ¨¡æ‹Ÿå¼€å§‹ï¼AIæ­£åœ¨æ‰®æ¼”æ‹…å¿§æ‚¨é€‰æ‹© â€œ{st.session_state.my_choice}â€ çš„å®¶äººã€‚")

        history = get_session_history("communication_session")
        with st.container():
            for msg in history.messages:
                avatar = "ğŸ§‘â€ğŸ’»" if isinstance(msg, HumanMessage) else "ğŸ§“"
                st.chat_message(msg.type, avatar=avatar).markdown(msg.content)

        if not st.session_state.get('debrief_requested', False):
            communication_prompt = ChatPromptTemplate.from_messages([
                ("system", GLOBAL_PERSONA + f"""
                ç°åœ¨ï¼Œä½ å°†æ‰®æ¼”ä¸€ä¸ªå…³å¿ƒå­©å­ä½†æ€æƒ³ç•¥æ˜¾ä¼ ç»Ÿçš„å®¶äººã€‚
                - ä½ çš„æ ¸å¿ƒæ‹…å¿§æ˜¯: "{st.session_state.family_concern}"
                - ä½ çš„å¯¹è¯ç›®æ ‡æ˜¯ï¼šåå¤ç¡®è®¤å­©å­æ˜¯å¦è€ƒè™‘æ¸…æ¥šäº†è¿™äº›æ‹…å¿§ï¼Œè€Œä¸æ˜¯è½»æ˜“è¢«è¯´æœã€‚
                - ä½ çš„è¯­æ°”åº”è¯¥åƒä¸€ä¸ªçœŸå®çš„ã€æœ‰è‡ªå·±ç«‹åœºå’Œæƒ…ç»ªçš„å®¶äººï¼Œå¯ä»¥å›ºæ‰§ï¼Œå¯ä»¥è¡¨è¾¾å¤±æœ›æˆ–ä¸è§£ï¼Œä½†æœ€ç»ˆçš„å‡ºå‘ç‚¹æ˜¯çˆ±å’Œå…³å¿ƒã€‚
                - ä¸è¦è½»æ˜“æ”¾å¼ƒä½ çš„æ‹…å¿§ï¼Œç›´åˆ°ç”¨æˆ·ç»™å‡ºäº†éå¸¸æœ‰è¯´æœåŠ›ã€èƒ½è®©ä½ å®‰å¿ƒçš„ç†ç”±ã€‚
                """),
                MessagesPlaceholder(variable_name="history"),
                ("human", "{input}")
            ])
            chain_with_history = RunnableWithMessageHistory(
                communication_prompt | llm,
                lambda s: get_session_history(s),
                input_messages_key="input",
                history_messages_key="history"
            )

            if user_input := st.chat_input("ä½ çš„å›åº”:"):
                with st.spinner("..."):
                    chain_with_history.invoke(
                        {"input": user_input},
                        config={"configurable": {"session_id": "communication_session"}}
                    )
                st.rerun()

            if len(history.messages) > 2:
                if st.button("ç»“æŸæ¨¡æ‹Ÿå¹¶è·å–å¤ç›˜å»ºè®®"):
                    st.session_state.debrief_requested = True
                    st.rerun()

        else:
            with st.container(border=True):
                st.info("å¯¹è¯å·²ç»“æŸã€‚AIæ•™ç»ƒæ­£åœ¨ä¸ºæ‚¨å¤ç›˜åˆšæ‰çš„æ²Ÿé€šè¡¨ç°...")
                full_conversation = "\n".join(
                    [f"{'æˆ‘' if isinstance(msg, HumanMessage) else 'å®¶äºº'}: {msg.content}" for msg in history.messages]
                )
                debrief_prompt = ChatPromptTemplate.from_template(GLOBAL_PERSONA + """
                ä½ ç°åœ¨åˆ‡æ¢å›èŒä¸šå‘å±•æ•™ç»ƒçš„è§’è‰²ã€‚ä»¥ä¸‹æ˜¯ä¸€ä»½ç”¨æˆ·ä¸ä½ æ‰®æ¼”çš„â€œå®¶äººâ€ä¹‹é—´çš„æ²Ÿé€šè®°å½•ã€‚
                ç”¨æˆ·çš„ç›®æ ‡æ˜¯è¯´æœå®¶äººï¼Œè®©ä»–ä»¬ç†è§£å¹¶å‡å°‘å¯¹è‡ªå·±èŒä¸šé€‰æ‹©({my_choice})çš„æ‹…å¿§({family_concern})ã€‚

                è¯·ä½ ä»ä¸€ä¸ªä¸“ä¸šæ²Ÿé€šæ•™ç»ƒçš„è§’åº¦ï¼Œå¯¹ç”¨æˆ·çš„è¡¨ç°è¿›è¡Œå…¨é¢ã€æœ‰å»ºè®¾æ€§çš„å¤ç›˜ã€‚å¤ç›˜æŠ¥å‘Šå¿…é¡»åŒ…æ‹¬ï¼š

                ### 1. æ²Ÿé€šäº®ç‚¹ (åšå¾—å¥½çš„åœ°æ–¹)
                - æŒ‡å‡ºç”¨æˆ·åœ¨å¯¹è¯ä¸­å±•ç°å‡ºçš„åŒç†å¿ƒã€æ¸…æ™°çš„é€»è¾‘æˆ–æœ‰æ•ˆå®‰æŠšæƒ…ç»ªçš„å…·ä½“è¯è¯­ã€‚

                ### 2. å¯ä¼˜åŒ–ç‚¹ (å¯ä»¥æ›´å¥½çš„åœ°æ–¹)
                - åˆ†æç”¨æˆ·åœ¨å“ªäº›åœ°æ–¹å¯èƒ½é”™å¤±äº†æœºä¼šï¼Œæˆ–è€…å“ªäº›å›åº”å¯èƒ½æ¿€åŒ–äº†çŸ›ç›¾ã€‚
                - æ˜¯å¦æœ‰æ•ˆå›åº”äº†å®¶äººçš„æ ¸å¿ƒå…³åˆ‡ç‚¹ï¼Ÿ

                ### 3. å…·ä½“è¯æœ¯å»ºè®®
                - é’ˆå¯¹å¯ä¼˜åŒ–ç‚¹ï¼Œæä¾›1-2ä¸ªå…·ä½“çš„ã€å¯ç›´æ¥ä½¿ç”¨çš„â€œè¯æœ¯â€æˆ–â€œè¡¨è¾¾æ–¹å¼â€å»ºè®®ã€‚ä¾‹å¦‚ï¼šâ€œå½“å®¶äººè¯´â€˜ä¸ç¨³å®šâ€™æ—¶ï¼Œä½ å¯ä»¥å°è¯•è¿™æ ·å›åº”ï¼šâ€˜æˆ‘ç†è§£æ‚¨çš„æ‹…å¿ƒï¼Œæˆ‘ä¹Ÿä¸ºè‡ªå·±è§„åˆ’äº†...â€™â€

                è¯·ä»¥å¯Œæœ‰åŒæƒ…å¿ƒå’Œå¯å‘æ€§çš„æ–¹å¼å‘ˆç°è¿™ä»½æŠ¥å‘Šã€‚
                ---
                å¯¹è¯è®°å½•å¦‚ä¸‹:
                {conversation_history}
                ---
                """)
                debrief_chain = debrief_prompt | llm

                with st.spinner("æ­£åœ¨ç”Ÿæˆæ²Ÿé€šå¤ç›˜æŠ¥å‘Š..."):
                    response_stream = debrief_chain.stream({
                        "my_choice": st.session_state.my_choice,
                        "family_concern": st.session_state.family_concern,
                        "conversation_history": full_conversation
                    })
                    st.subheader("ğŸ“‹ æ²Ÿé€šè¡¨ç°å¤ç›˜æŠ¥å‘Š")
                    st.write_stream(response_stream)


def render_company_info_mode(llm):
    """æ¸²æŸ“ä¼ä¸šä¿¡æ¯é€Ÿè§ˆæ¨¡å¼çš„ UI å’Œé€»è¾‘ã€‚"""
    st.header("æ¨¡å¼å››: ä¼ä¸šä¿¡æ¯é€Ÿè§ˆ")
    with st.container(border=True):
        st.info("è¯·è¾“å…¥å…¬å¸å…¨åï¼ŒAIå°†æ¨¡æ‹Ÿç½‘ç»œæŠ“å–å¹¶ä¸ºæ‚¨ç”Ÿæˆä¸€ä»½æ ¸å¿ƒä¿¡æ¯é€Ÿè§ˆæŠ¥å‘Šã€‚")
        chain = ChatPromptTemplate.from_template(GLOBAL_PERSONA + """
        You are a professional business analyst AI. Your task is to provide a concise and structured overview of a given company, as if you had scraped its public information from the web. The report should be well-organized for a job seeker.

        Company Name: {company_name}

        Please structure your report in markdown with the following sections:

        ### 1. å…¬å¸ç®€ä»‹ (Company Overview)
        - Core business, main products/services, and target market.

        ### 2. è¿‘æœŸåŠ¨æ€ä¸æ–°é—» (Recent Developments & News)
        - Summarize 1-2 key recent events, such as major product launches, financial results, or strategic partnerships.

        ### 3. ä¼ä¸šæ–‡åŒ–ä¸ä»·å€¼è§‚ (Culture & Values)
        - Briefly describe the stated or perceived company culture.

        ### 4. çƒ­é—¨æ‹›è˜æ–¹å‘ (Hiring Trends)
        - Based on publicly available information, what types of roles or departments seem to be in high demand at the company? (e.g., "Engineering, particularly in AI/ML", "Sales and Business Development").

        Your tone should be professional, objective, and informative.
        """) | llm
        company_name = st.text_input("è¯·è¾“å…¥å…¬å¸åç§°:", placeholder="ä¾‹å¦‚ï¼šé˜¿é‡Œå·´å·´ã€è…¾è®¯ã€å­—èŠ‚è·³åŠ¨")
        if st.button("ç”Ÿæˆé€Ÿè§ˆæŠ¥å‘Š", use_container_width=True):
            if not company_name:
                st.warning("è¯·è¾“å…¥å…¬å¸åç§°ã€‚")
            else:
                with st.spinner(f"æ­£åœ¨ç”Ÿæˆå…³äºâ€œ{company_name}â€çš„ä¿¡æ¯æŠ¥å‘Š..."):
                    response_stream = chain.stream({"company_name": company_name})
                    st.markdown("---");
                    st.subheader(f"ğŸ“„ {company_name} - æ ¸å¿ƒä¿¡æ¯é€Ÿè§ˆ");
                    st.write_stream(response_stream)


def render_panoramic_mode(llm):
    """æ¸²æŸ“èŒä¸šè·¯å¾„å…¨æ™¯è§„åˆ’æ¨¡å¼ã€‚"""
    st.header("æ¨¡å¼äº”: èŒä¸šè·¯å¾„å…¨æ™¯è§„åˆ’")
    history = get_session_history("panoramic_session")
    stage = st.session_state.get('panoramic_stage', 1)

    # æ¸²æŸ“å†å²æ¶ˆæ¯
    for msg in history.messages:
        avatar = "ğŸ§‘â€ğŸ’»" if isinstance(msg, HumanMessage) else "ğŸ¤–"
        with st.chat_message(msg.type, avatar=avatar):
            st.markdown(msg.content, unsafe_allow_html=True)

    meta_prompt_template = GLOBAL_PERSONA + """
    You are an expert career strategist, guiding the user through a panoramic career path analysis based on the "Specialty -> Profession -> Enterprise -> Industry Chain -> Industry" framework. You are currently in Stage {current_stage}.

    User's Core Competency Profile: {user_profile}
    User's Chosen Profession(s): {chosen_professions}
    User's Chosen Company Type: {chosen_company_type}

    Your Task is to execute the current stage's logic.

    --- STAGE-SPECIFIC INSTRUCTIONS ---

    **Stage 1 (Core Competency Assessment):**
    The user has just provided their self-assessment. Your task is to briefly summarize their core competency profile in an encouraging tone to confirm understanding.
    *Edge Case Handling:* If the user's input is too vague or contradictory (e.g., skills and motivation mismatch), your first task is to ask a clarifying question instead of summarizing. For example: "æˆ‘æ³¨æ„åˆ°æ‚¨çš„æŠ€èƒ½åå‘æŠ€æœ¯åˆ†æï¼Œä½†åŠ¨æœºæ›´ä¾§é‡äºäººé™…æ²Ÿé€šã€‚æ‚¨èƒ½å¦åˆ†äº«ä¸€ä¸ªå°†ä¸¤è€…ç»“åˆçš„ç»å†ï¼Ÿè¿™æœ‰åŠ©äºæˆ‘æ›´ç²¾å‡†åœ°ä¸ºæ‚¨åŒ¹é…èŒä¸šã€‚"

    **Stage 2 (Profession Concretization):**
    Based on the user's profile, brainstorm and present 3-5 concrete professions (èŒä¸š). For each, explain its connection to the user's skills and motivations in one sentence.
    *Format:* Use a markdown list. Example: "- **æ•°æ®åˆ†æå¸ˆ**: èƒ½å¾ˆå¥½åœ°ç»“åˆæ‚¨åœ¨ `æ•°æ®å¤„ç†` ä¸Šçš„æŠ€èƒ½å’Œ `é€šè¿‡æ•°æ®æ´å¯Ÿè¶‹åŠ¿` çš„åŠ¨æœºã€‚"
    Finally, prompt the user to select 1-2 professions they are most interested in.

    **Stage 3 (Representative Enterprise Targeting):**
    Based on the user's chosen profession, identify 3-5 representative companies (ä¼ä¸š). Include a mix of stable, established companies and innovative, high-growth ones. Provide a one-sentence description for each.
    *Edge Case Handling:* If the field is too new or niche for clear representative companies, state it honestly. Example: "è¿™æ˜¯ä¸€ä¸ªéå¸¸å‰æ²¿å’Œä»¤äººå…´å¥‹çš„é¢†åŸŸï¼è¿™æ„å‘³ç€è·¯å¾„å°šæœªå®šå‹ï¼Œå……æ»¡äº†æœºä¼šä¸æŒ‘æˆ˜ã€‚è®©æˆ‘ä»¬ä¸“æ³¨äºæ„å»ºæ‚¨çš„å¯è¿ç§»æ ¸å¿ƒèƒ½åŠ›ï¼Œå¹¶æ‰¾å‡ºè¿™ä¸ªé¢†åŸŸçš„å¼€åˆ›æ€§ç»„ç»‡ã€‚"
    Finally, ask the user which type of company they lean towards (e.g., "å®‰å®šå‹" or "æˆé•¿å‹").

    **Stage 4 (Industry Chain Position Analysis):**
    Based on the chosen profession and company type, explain the concept of the industry chain (äº§ä¸šé“¾) in simple terms. Describe where the target role/company typically fits. Mention related upstream/downstream sectors.

    **Stage 5 (Industry Trend & Transformation Insight):**
    Provide a concise analysis of the broader industry (è¡Œä¸š). Summarize 2-3 key trends and 1-2 potential future transformations. Connect these back to the user's potential role.
    *Edge Case Handling:* If the industry is declining, handle it sensitively. Present the data and then shift focus to adjacent, growing industries where the user's core competencies are valuable. Example: "æ•°æ®æ˜¾ç¤ºä¼ ç»Ÿçš„ [è¡Œä¸šX] æ­£é¢ä¸´è½¬å‹æŒ‘æˆ˜ï¼Œä½†æ‚¨æ‰€å…·å¤‡çš„ [æŠ€èƒ½A] å’Œ [æŠ€èƒ½B] åœ¨é«˜é€Ÿå‘å±•çš„ [è¡Œä¸šY] é¢†åŸŸæ­£å˜å¾—ç‚™æ‰‹å¯çƒ­ã€‚æˆ‘ä»¬ä¸å¦¨æ¢è®¨ä¸€ä¸‹ï¼Œå¦‚ä½•å°†æ‚¨çš„æ ¸å¿ƒèƒ½åŠ›è¿ç§»åˆ°è¿™ä¸ªæ–°èµ›é“ã€‚"

    **Stage 6 (Summary & Strategic Planning):**
    Generate a full markdown report summarizing findings from stages 2-5. Conclude with a "æˆ˜ç•¥å±•æœ› (Strategic Outlook)" section. Pose 2-3 forward-looking questions to help the user plan their next steps.
    """

    chain = ChatPromptTemplate.from_template(meta_prompt_template) | llm

    if stage == 1 and st.session_state.user_profile is None:
        st.markdown(
            "> ä½ å¥½ï¼æˆ‘æ˜¯ä½ çš„èŒä¸šè·¯å¾„è§„åˆ’åŠ©æ‰‹ã€‚æƒ³ä¸æƒ³åƒæ‰“å¼€ä¸€å¼ åœ°å›¾ä¸€æ ·ï¼Œæ¸…æ™°åœ°çœ‹åˆ°ä½ çš„ä¸ªäººèƒ½åŠ›å¦‚ä½•ä¸€æ­¥æ­¥é€šå¾€ä¸€ä¸ªå…·ä½“çš„è¡Œä¸šï¼Œå¹¶çœ‹æ¸…æœªæ¥çš„å‘å±•è¶‹åŠ¿ï¼Ÿ\n> è¿™ä¸ªâ€œèŒä¸šè·¯å¾„å…¨æ™¯è§„åˆ’â€æ¨¡å¼ï¼Œå°†å¼•å¯¼ä½ ä»è‡ªæˆ‘è®¤çŸ¥å‡ºå‘ï¼Œè¿æ¥èŒä¸šã€ä¼ä¸šã€äº§ä¸šé“¾ï¼Œæœ€ç»ˆæ´å¯Ÿæ•´ä¸ªè¡Œä¸šçš„æœªæ¥ã€‚è®©æˆ‘ä»¬å¼€å§‹ç¬¬ä¸€æ­¥ï¼Œä¹Ÿæ˜¯æœ€é‡è¦çš„ä¸€æ­¥ï¼š**è®¤è¯†ä½ è‡ªå·±**ã€‚")
        with st.form("profile_form"):
            st.subheader("è¯·æ ¹æ®ä»¥ä¸‹äº”ä¸ªç»´åº¦ï¼Œæè¿°ä½ çš„â€œæ ¸å¿ƒèƒ½åŠ›â€ï¼š")
            edu = st.text_area("å­¦å†èƒŒæ™¯ (Education)", placeholder="ä½ çš„ä¸“ä¸šã€å­¦ä½ã€ä»¥åŠç›¸å…³çš„æ ¸å¿ƒè¯¾ç¨‹")
            skills = st.text_area("æ ¸å¿ƒæŠ€èƒ½ (Skills)",
                                  placeholder="ä½ æœ€æ“…é•¿çš„3-5é¡¹ç¡¬æŠ€èƒ½æˆ–è½¯æŠ€èƒ½ï¼Œå¦‚ç¼–ç¨‹ã€äº§å“è®¾è®¡ã€æ²Ÿé€šã€æ•°æ®åˆ†æç­‰")
            exp = st.text_area("ç›¸å…³ç»éªŒ (Experience)", placeholder="ç›¸å…³çš„å®ä¹ ã€å·¥ä½œé¡¹ç›®ã€æˆ–ä¸ªäººä½œå“é›†")
            char = st.text_area("å“è¡Œç‰¹è´¨ (Character)",
                                placeholder="ä½ è®¤ä¸ºè‡ªå·±æœ€é‡è¦çš„èŒä¸šå“è¡Œæˆ–å·¥ä½œé£æ ¼ï¼Œå¦‚ä¸¥è°¨ã€åˆ›æ–°ã€æœ‰è´£ä»»å¿ƒ")
            motiv = st.text_area("å†…åœ¨åŠ¨æœº (Motivation)", placeholder="åœ¨å·¥ä½œä¸­ï¼Œä»€ä¹ˆæœ€èƒ½ç»™ä½ å¸¦æ¥æˆå°±æ„Ÿå’Œæ»¡è¶³æ„Ÿï¼Ÿ")

            submitted = st.form_submit_button("æäº¤æˆ‘çš„èƒ½åŠ›ç”»åƒ", use_container_width=True)
            if submitted:
                if not all([edu, skills, exp, char, motiv]):
                    st.warning("è¯·å¡«å†™æ‰€æœ‰äº”ä¸ªç»´åº¦çš„ä¿¡æ¯ï¼Œä»¥ä¾¿è¿›è¡Œå‡†ç¡®åˆ†æã€‚")
                else:
                    profile_text = f"å­¦å†èƒŒæ™¯: {edu}\næ ¸å¿ƒæŠ€èƒ½: {skills}\nç›¸å…³ç»éªŒ: {exp}\nå“è¡Œç‰¹è´¨: {char}\nå†…åœ¨åŠ¨æœº: {motiv}"
                    st.session_state.user_profile = profile_text
                    history.add_user_message(f"è¿™æ˜¯æˆ‘çš„èƒ½åŠ›ç”»åƒï¼š\n{profile_text}")
                    st.session_state.panoramic_stage = 2
                    st.rerun()

    elif st.session_state.user_profile is not None and stage < 7:
        if f"stage_{stage}_started" not in st.session_state:
            with st.chat_message("ai", avatar="ğŸ¤–"):
                with st.spinner("AI æ­£åœ¨ä¸ºæ‚¨åˆ†æä¸‹ä¸€æ­¥..."):
                    response_stream = chain.stream({
                        "current_stage": stage,
                        "user_profile": st.session_state.user_profile,
                        "chosen_professions": st.session_state.get('chosen_professions', 'N/A'),
                        "chosen_company_type": st.session_state.get('chosen_company_type', 'N/A')
                    })
                    response_content = st.write_stream(response_stream)
                    history.add_ai_message(response_content)
            st.session_state[f"stage_{stage}_started"] = True
            st.rerun()

        if stage < 6:
            if user_input := st.chat_input("è¯·åœ¨æ­¤è¾“å…¥æ‚¨çš„é€‰æ‹©æˆ–æƒ³æ³•..."):
                history.add_user_message(user_input)
                if stage == 2:
                    st.session_state.chosen_professions = user_input
                elif stage == 3:
                    st.session_state.chosen_company_type = user_input
                st.session_state.panoramic_stage = stage + 1
                st.rerun()
        else:
            with st.container(border=True):
                st.success("æ­å–œï¼æ‚¨å·²å®Œæˆæœ¬æ¬¡èŒä¸šè·¯å¾„å…¨æ™¯è§„åˆ’ã€‚")
                clarity_score = st.radio(
                    "**æœ¬æ¬¡åˆ†æåœ¨å¤šå¤§ç¨‹åº¦ä¸Šæå‡äº†æ‚¨å¯¹ä¸ªäººèŒä¸šè·¯å¾„çš„æ¸…æ™°åº¦ï¼Ÿ** (5åˆ†ä»£è¡¨éå¸¸æ¸…æ™°)",
                    options=[1, 2, 3, 4, 5], index=None, horizontal=True)
                if clarity_score:
                    st.info(f"æ„Ÿè°¢æ‚¨çš„è¯„åˆ†ï¼å¸Œæœ›è¿™æ¬¡è§„åˆ’å¯¹æ‚¨æœ‰å¸®åŠ©ã€‚")


# --- ä¸»åº”ç”¨é€»è¾‘ ---
def main():
    """ä¸»å‡½æ•°ï¼Œè¿è¡Œ Streamlit åº”ç”¨ã€‚"""
    llm = get_llm_instance()
    if not llm:
        st.error("æ— æ³•åˆå§‹åŒ–è¯­è¨€æ¨¡å‹ï¼Œåº”ç”¨ç¨‹åºæ— æ³•å¯åŠ¨ã€‚è¯·æ£€æŸ¥æ‚¨çš„ API Key è®¾ç½®ã€‚")
        st.stop()

    with st.sidebar:
        # st.image("https://s2.loli.net/2024/05/31/vCSO5WwR6r2zMGU.png", width=150) # <-- å·²å°†æ­¤è¡Œæ³¨é‡Šæ‰ï¼Œè§£å†³404é—®é¢˜
        if st.session_state.current_mode != "menu":
            if st.button("â†©ï¸ è¿”å›ä¸»èœå•"):
                for key in list(st.session_state.keys()):
                    if key != 'current_mode':
                        del st.session_state[key]
                st.session_state.current_mode = "menu"
                st.rerun()
        st.markdown("---")
        st.caption("Â© 2025 æ™ºæ…§èŒä¸šè¾…å¯¼ V5.2")

    modes = {
        "menu": render_menu,
        "exploration": render_exploration_mode,
        "decision": render_decision_mode,
        "communication": render_communication_mode,
        "company_info": render_company_info_mode,
        "panoramic": render_panoramic_mode,
    }

    mode_func = modes.get(st.session_state.current_mode, render_menu)

    if st.session_state.current_mode == "menu":
        mode_func()
    else:
        mode_func(llm)


if __name__ == "__main__":
    main()